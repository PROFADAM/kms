kmsPeers:
  # Defines either the peer ID when count=1 or the start ID of a set of peers when count>1
  id: 1
  # The number of peers managed by the StatefulSets
  count: 1

kmsConnector:
  enabled: true
  nameOverride:
  image:
    name: ghcr.io/zama-ai/kms-connector
    tag: latest
  config:
    chainId: 1337
    gatewayL2RpcUrl: "ws://localhost:8757"
    channelSize: "1000"
  contractAddress:
    configmap:
      name: kms-sc-deploy-kms-sc-addresses
      httpzAddressKey: HTTPZ_CONTRACT_ADDRESS
      decryptionManagerAddressKey: DECRYPTION_MANAGER_CONTRACT_ADDRESS
  storage:
    # storageClassName: gp3
    capacity: 5Gi
  wallet:
    secret:
      name: kms-connector-keys
  nodeSelector:
  affinity:
  tolerations:

kmsCore:
  enabled: true
  nameOverride:
  addressOverride:
  image:
    name: ghcr.io/zama-ai/kms-service
    tag: latest
    pullPolicy: Always
  serviceAccountName:
  envFrom:
    configmap:
      name:
  thresholdMode:
    enabled: false
    # If left unset, the chart will generate the list automatically based on pod replicas of the statefulset
    peersList:
    #  - id: 1
    #    host: kms-service-core-1
    #    port: 50001
    #  - id: 2
    #    host: kms-service-core-2
    #    port: 50001
    dec_capacity: 10000
    min_dec_cache: 6000
    num_sessions_preproc: 2
    decryption_mode: "NoiseFloodSmall"
  nitroEnclave:
    enabled: false
    debug: true
    # Enclave CPU count, must be a multiple of 2 since whole cores (not hyperthreads) are sliced off and dedicated to the enclave
    cpuCount: 6
    # Enclave Memory in GiB
    memoryGiB: 20
    cid: 20
    eifPath: /app/kms/core/service/enclave.eif
    userId: 10003
    groupId: 10002
    ports:
      tracing: 4317
      # For AWS authentication, set the `imds` or `sts` ports
      # To authenticate using either IMDS (with the Kubernetes node EC2 instance role) or STS (with the IRSA)
      imds: 5000
      sts: 5500
      s3: 6000
      awskms: 7000
      peer: 10000
      # Important, don't bind to port 9000 as it is reserved by Nitro for communicating with the enclave.
  publicVault:
    s3:
      enabled: true
      bucket: kms-public
      path: kms
  privateVault:
    s3:
      enabled: false
      bucket: kms-private
      path: kms
    awskms:
      enabled: false
      keychain: awskms://symm/00000000-0000-0000-0000-000000000000
  aws:
    roleArn:
    region: eu-west-1
  storage:
    # storageClassName: gp3
    capacity: 5Gi
  ports:
    client: 50100
    peer: 50001
    metrics: 9646
  workdir: /root
  serviceMonitor:
    enabled: false
  # Note: these requests/limits is only for non-enclave workloads, this will not be allocated to the kms-core process running in Nitro
  resources:
    requests: {}
      # memory: 1Gi
      # cpu: 1
    limits:
      # memory: 30Gi
      ephemeralStorage: 1Gi
      grpcTimeout: 360
      grpcMaxMessageSize: 2097520
  nodeSelector:
  affinity:
  tolerations:
mtls:
  enabled: false

kmsCoreClient:
  enabled: false
  nameOverride:
  image:
    name: ghcr.io/zama-ai/kms-core-client
    tag: latest
  envFrom:
    configmap:
      name:
  num_majority: 2
  num_reconstruct: 3
  decryption_mode: "NoiseFloodSmall"
  fhe_parameter: Test
  nodeSelector:
  affinity:
  tolerations:

kmsInit:
  enabled: false
  nodeSelector:
  affinity:
  tolerations:

kubeUtils:
  image:
    name: ghcr.io/zama-ai/kube-utils
    tag: 0.2.0
    pullPolicy: Always

runMode: dev

redis:
  enabled: false
  host: "redis://redis-master.common.svc.cluster.local"

tracing:
  enabled: false
  endpoint: "http://otel-deployment-opentelemetry-collector.observability.svc.cluster.local:4317"
  otlp_timeout_ms: 10000

minio:
  enabled: false
  fullnameOverride: minio
  auth:
    rootUser: minio-admin
    rootPassword: minio-admin
  provisioning:
    enabled: true
    buckets:
      - name: kms-public
        region: eu-west-1
    users:
      - username: kms-access-key-id
        password: kms-secret-access-key
        policies:
          - readwrite
    extraCommands:
      - "mc anonymous set public provisioning/kms-public"

rustLog: info

podSecurityContext:
  # To set when the image will support non root user
  #  runAsUser: 1000
  #  runAsGroup: 1000
  #  fsGroup: 1000
  #  runAsNonRoot: true
  allowPrivilegeEscalation: false
  readOnlyRootFilesystem: true
  capabilities:
    drop:
      - ALL
  privileged: false

podSecurityContextForEnclave:
  fsGroup: 1001     # Keep this as 1001 to match device group
  supplementalGroups: [1001]  # Add device group as supplemental

kyverno:
  enabled: false

# Cronjob kubernetes
kmsCoreClientTesting:
  enabled: false
  schedule: "30 0 * * *"
